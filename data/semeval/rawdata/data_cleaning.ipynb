{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "The first step is to set up the file reading processes. One of the things to remember at this stage is that since testing the models occur at the process of training by withholding a untouched set of data and testing it every so often, joining the training and development set of data renders more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "fear_files = ['train/EI-oc-En-fear-train.txt', 'dev/2018-EI-oc-En-fear-dev.txt']\n",
    "anger_files = ['train/EI-oc-En-anger-train.txt', 'dev/2018-EI-oc-En-anger-dev.txt']\n",
    "joy_files = ['train/EI-oc-En-joy-train.txt', 'dev/2018-EI-oc-En-joy-dev.txt']\n",
    "sad_files = ['train/EI-oc-En-sadness-train.txt', 'dev/2018-EI-oc-En-sadness-dev.txt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a function that takes a list of files paths as a parameters, and combines the files into one single data frame. This is the base frame for the rest of the cleaning procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(file_list):\n",
    "    frames = []\n",
    "    for f in file_list:\n",
    "        frames.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    \n",
    "    return pd.concat(frames)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to remove the fluff of the classes. `TensorFlow` will want to be fed numerical classes so the first step will be to pull out the numebrs from the 'Intensity Class' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes(frame, tri_class=False):\n",
    "    int_class = list(map(lambda x: int(re.findall('\\d+', x)[0]), frame['Intensity Class']))\n",
    "    frame['Sentiment'] = int_class\n",
    "    \n",
    "    if tri_class:\n",
    "        frame['Sentiment'] = frame['Sentiment'].map({2: 1})\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we need to downsample to the frame so that each class is evenly represented. The downsampling function randomizes and samples the rows for each class to match the number of rows of the least represented class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(frame):\n",
    "    # split data across sentiments\n",
    "    sub_list = []\n",
    "    for v in pd.unique(frame['Sentiment']):\n",
    "        sub_list.append(frame.loc[frame['Sentiment'] == v])\n",
    "    \n",
    "    # find number of rows for each subset \n",
    "    sub_row_lengths = [len(d) for d in sub_list]\n",
    "    \n",
    "    downsamp_num = min(sub_row_lengths)\n",
    "    \n",
    "    # downsample based off of the smallest subset \n",
    "    downsamped = pd.concat([d.sample(downsamp_num) for d in sub_list])\n",
    "    \n",
    "    return downsamped.sample(len(downsamped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap this all up into a class and voila..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataShogun(object):\n",
    "    \"\"\"DataShogun is a data preparation class for data drawn from SentiEval.\n",
    "    \"\"\"\n",
    "    def __init__(self, tri_class=False, *paths):\n",
    "        self.files = paths\n",
    "        self.combined = self._combine_data(paths)\n",
    "        self.clean_class = self._convert_classes(self.combined, tri_class)\n",
    "        self.downsamped = self._downsample(self.clean_class)\n",
    "        self.final_frame = self.downsamped.rename(columns={\"Tweet\": \"SentimentText\"})\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _combine_data(self, file_list):\n",
    "        frames = []\n",
    "        for f in file_list:\n",
    "            frames.append(pd.read_csv(f, sep=\"\\t\"))\n",
    "    \n",
    "        return pd.concat(frames)\n",
    "    \n",
    "    def _convert_classes(self, frame, tri_class=False):\n",
    "        int_class = list(map(lambda x: int(re.findall('\\d+', x)[0]), frame['Intensity Class']))\n",
    "        frame['Sentiment'] = int_class\n",
    "        \n",
    "        if tri_class:\n",
    "            frame['Sentiment'] = frame['Sentiment'].map({0: 0, 1:1, 2: 1, 3: 2})\n",
    "        return frame\n",
    "    \n",
    "    def _downsample(self, frame):\n",
    "        # split data across sentiments\n",
    "        sub_list = []\n",
    "        for v in pd.unique(frame['Sentiment']):\n",
    "            sub_list.append(frame.loc[frame['Sentiment'] == v])\n",
    "        \n",
    "        # find number of rows for each subset \n",
    "        sub_row_lengths = [len(d) for d in sub_list]\n",
    "        \n",
    "        downsamp_num = min(sub_row_lengths)\n",
    "        \n",
    "        # downsample based off of the smallest subset \n",
    "        downsamped = pd.concat([d.sample(downsamp_num) for d in sub_list])\n",
    "        \n",
    "        return downsamped.sample(len(downsamped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create separate DataShogun objects for each of the four emotions and then write them to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fear = DataShogun(True, 'train/EI-oc-En-fear-train.txt', 'dev/2018-EI-oc-En-fear-dev.txt')\n",
    "anger = DataShogun(True, 'train/EI-oc-En-anger-train.txt', 'dev/2018-EI-oc-En-anger-dev.txt')\n",
    "sad = DataShogun(True, 'train/EI-oc-En-sadness-train.txt', 'dev/2018-EI-oc-En-sadness-dev.txt')\n",
    "joy = DataShogun(True, 'train/EI-oc-En-joy-train.txt', 'dev/2018-EI-oc-En-joy-dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fear.final_frame.to_csv(\"train/training_fear_tri_class.csv\")\n",
    "anger.final_frame.to_csv(\"train/training_anger_tri_class.csv\")\n",
    "sad.final_frame.to_csv(\"train/training_sad_tri_class.csv\")\n",
    "joy.final_frame.to_csv(\"train/training_job_tri_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  SentimentText  Affect Dimension  Intensity Class\n",
       "Sentiment                                                       \n",
       "0          217            217               217              217\n",
       "1          217            217               217              217\n",
       "2          217            217               217              217"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
