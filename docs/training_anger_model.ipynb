{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Anger Model\n",
    "\n",
    "**SPECIAL NOTE:**\n",
    "This file corrresponds to the training of the anger model referenced in the *The Border Effect: Analyzing the Geographic Relationship of Angry Immigration Tweets Classified by a Gated Recurrent Unit* article.\n",
    "\n",
    "This file will take you through the steps of training a tweet anger classification model using [SemEval 2018 Task 1 data](https://competitions.codalab.org/competitions/17751) using [pretrained word vectors](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "## Training Data\n",
    "path to training data set: `data/semeval/rawdata/train/training_anger_tri_class.csv`\n",
    "\n",
    "Attributes of Interest:\n",
    "\n",
    "Column name     | Description\n",
    "-----------     | -----------\n",
    "`SentimentText` | Tweet text\n",
    "`Sentiment`     | Class (0: not angry, 1: somewhat angry, 2: angry)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pretrained Word Vectors\n",
    "\n",
    "Download the `glove.twitter.27B.zip` from [here](https://nlp.stanford.edu/projects/glove/) and unzip the file. The run the following code to preprocess the pretrained word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THIS CODE TO MATCH THE PATH TO THE `glove.twitter.27B.100d.txt` file\n",
    "txt_file = 'path/to/glove.twitter.27B.100d.txt' \n",
    "\n",
    "# MODIEFY THIS CODE. THIS IS WHERE YOU WILL SAVE THE PREPROCESSED `np.array`s VECTORS\n",
    "preprocessed_save_path = 'path/to/preprocess_pretrained_vectors.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(txt_file, \"r\") as f:\n",
    "    file = f.read()\n",
    "    li = file.split('\\n')\n",
    "    \n",
    "    # empty placeholder lists\n",
    "    words = []\n",
    "    vectors = []\n",
    "    counter = 0\n",
    "\n",
    "    # split string list and create word vector lists\n",
    "    for i in li[0: len(li) -1]:\n",
    "        try: \n",
    "            words.append(i.split(' ')[0])\n",
    "            vectors.append([float(v) for v in i.split(' ')[1: 101]])\n",
    "        except:\n",
    "            print(counter)\n",
    "        counter += 1\n",
    "    \n",
    "    # add blank to the list of words\n",
    "    words = [''] + words\n",
    "    \n",
    "    # create 0 vector for blank reference\n",
    "    vectors = [[0.0 for i in range(100)]] + vectors\n",
    "    \n",
    "    # create arrays\n",
    "    vocab = np.array(words)\n",
    "    embeddings = np.array(vectors)\n",
    "    \n",
    "    # saved array objects \n",
    "    np.savez(preprocessed_save_path, vocab=vocab, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Anger Model\n",
    "\n",
    "Now that the word vectors are preprocessed, training the model is simple. From inside the `lovelace/` directory run the following. Be sure to modify the `--embedding_file` to where you saved the preprocessed word vectors.\n",
    "\n",
    "```bash\n",
    "python train_scully.py --data_file data/semeval/rawdata/train/training_anger_tri_class.csv \\\n",
    " --embedding_file path/to/preprocess_pretrained_vectors.npz  \\\n",
    " --test_size 0.15 --batch_size 128 --hidden_dim 120 --num_classes 3 --num_epochs 5000 \\\n",
    " --learning_rate 0.00001 --embed_dim 100 --cell_type \"gru\"\n",
    "```\n",
    "\n",
    "A model will be saved and the file name and path will be printed to the terminal. At any moment you can stop the training of the model by pressing `cmd/ctrl + c`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Novel Data\n",
    "\n",
    "To classify novel data, make sure you keep reference of the trained model path (it should look something like this `logs/rnn/22_Feb_2018-20_22_02`) and know the column name of the text attribute in the data file you are wanting to classify. The output file is where you would like to save the output to.\n",
    "\n",
    "Run the following from the terminal\n",
    "\n",
    "```bash\n",
    "python predict.py --logdir path/to/model/dir --data_file path/to/novel/data.csv \\ \n",
    " --output_file path/to/save/file.csv --text_name 'text_attribute_name' --delimiter ',' --qchar '\"'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
